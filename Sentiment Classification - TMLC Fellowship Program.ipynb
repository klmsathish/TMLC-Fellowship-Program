{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<center><h1 class=\"list-group-item list-group-item-success\">Twitter Sentiment Analysis</h1></center>","metadata":{}},{"cell_type":"markdown","source":"## Name : M Sathishkumar\n\n## Topic : NLP (Sentiment Classification)\n\n## TMLC Fellowship Program","metadata":{}},{"cell_type":"markdown","source":"<img src = \"https://res.cloudinary.com/qna/image/upload/v1635170410/sentiment-points.a502b2c_pyfy2i.png\" width = 500>","metadata":{}},{"cell_type":"markdown","source":"<div style=\"background:#c72e57;color:#fff;padding:1em 2em 1.5em 2em;border-radius: 3px;font-weight:bold\">\n    <strong>\n        <h4 style = \"color:#fff\"><font size = 4>Problem Statement</font></h4>\n    </strong>\n</div><br>\n<font size = 3.9 color = \"brown\">Classify the tweets by implementing any NLP approach for Sentiment analysis on the provided dataset. The objective is to recognize whether the given tweet is oriented as negative (-1), neutral (0), or positive (1) tone. Focus majorly on unique preprocessing techniques.</font>\n\n\n","metadata":{}},{"cell_type":"markdown","source":"<div style=\"background:#c72e57;color:#fff;padding:1em 2em 1.5em 2em;border-radius: 3px;font-weight:bold\">\n    <strong>\n        <h4 style = \"color:#fff\"><font size = 4>Context</font></h4>\n    </strong>\n</div><br>\n<font size = 3.9 color = \"brown\">Sentiment analysis studies the subjective information in an expression, that is, the opinions, appraisals, emotions, or attitudes towards a topic, person or entity.The dataset has three sentiments namely, negative(-1), neutral(0), and positive(+1).</font>","metadata":{}},{"cell_type":"markdown","source":"<div style=\"background:#c72e57;color:#fff;padding:1em 2em 1.5em 2em;border-radius: 3px;font-weight:bold\">\n    <strong>\n        <h4 style = \"color:#fff\"><font size = 4>Data Overview</font></h4>\n    </strong>\n</div><br>\n<font size = 3.5 color = \"brown\">The dataset contains information about<br><br>\n    <font color = \"red\">\n        <ol>\n    <li>Tweet - Message Tweeted</li><br>\n    <li>label - Sentiment for the tweet</li>\n        </ol>\n    </font>\n</font>\n","metadata":{}},{"cell_type":"markdown","source":"<div style=\"background:#c72e57;color:#fff;padding:1em 2em 1.5em 2em;border-radius: 3px;font-weight:bold\">\n    <strong>\n        <h4 style = \"color:#fff\"><font size = 4>Contents</font></h4>\n    </strong>\n</div>\n<font size = 3.5 color = \"blue\">\n    <ol>\n    <br><br><li>Importing Packages</li><br>\n    <li>Importing Data</li><br>\n    <li>Analysing Data</li><br>\n    <li>Data Visualization</li><br>\n    <li>Data Preprocessing</li><br>\n    <li>Training Models</li><br>\n    <li>Evaluation Metrics</li><br>\n    <li>Dumping Model</li><br>\n    <li>Prediction</li><br>\n    </ol>\n</font>","metadata":{}},{"cell_type":"markdown","source":"<div style=\"background:#c72e57;color:#fff;padding:1em 2em 1.5em 2em;border-radius: 3px;font-weight:bold\">\n    <strong>\n        <h4 style = \"color:#fff\"><font size = 4>1. Importing Packages</font></h4>\n    </strong>\n</div>","metadata":{}},{"cell_type":"code","source":"# Importing Packages\nimport warnings\nwarnings.filterwarnings(\"ignore\") \nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nfrom wordcloud import WordCloud,STOPWORDS,ImageColorGenerator\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, HashingVectorizer\nfrom sklearn.model_selection import train_test_split\nimport urllib.request\nimport re\nimport nltk\nnltk.download('stopwords', quiet=True)\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"background:#c72e57;color:#fff;padding:1em 2em 1.5em 2em;border-radius: 3px;font-weight:bold\">\n    <strong>\n        <h4 style = \"color:#fff\"><font size = 4>2. Importing Data</font></h4>\n    </strong>\n</div>","metadata":{}},{"cell_type":"code","source":"# Reading Data\ndf = pd.read_csv('../input/twitter-sentiment-dataset/Twitter_Data.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"background:#c72e57;color:#fff;padding:1em 2em 1.5em 2em;border-radius: 3px;font-weight:bold\">\n    <strong>\n        <h4 style = \"color:#fff\"><font size = 4>3. Analysing Data</font></h4>\n    </strong>\n</div>\n","metadata":{}},{"cell_type":"code","source":"# Data Sample\ndf.sample(5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking for NA Values\ndf.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<font color = \"brown\" size = 4> Very Less NA ValuesðŸ˜Š. We can drop them</font>","metadata":{}},{"cell_type":"code","source":"# Distribution of different classes in sentiment\ndef count_values_in_column(data,feature):\n    total=data.loc[:,feature].value_counts(dropna=False)\n    percentage=round(data.loc[:,feature].value_counts(dropna=False,normalize=True)*100,2)\n    return pd.concat([total,percentage],axis=1,keys=[\"Total\",\"Percentage\"])\ncount_values_in_column(df,\"category\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<font color = \"brown\" size = 4>Insights\n    <ul>\n    <li>In this data, we have more than 40% positive tweets</li>\n    <li>Negative Tweets are with low numbers and only 50% in count compared to positive tweets</li></ul>\n</font>","metadata":{}},{"cell_type":"code","source":"# Segrating based on different sentiments\ndf_negative = df[df[\"category\"]==-1]\ndf_positive = df[df[\"category\"]==1]\ndf_neutral = df[df[\"category\"]==0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"background:#c72e57;color:#fff;padding:1em 2em 1.5em 2em;border-radius: 3px;font-weight:bold\">\n    <strong>\n        <h4 style = \"color:#fff\"><font size = 4>4. Data Visualization</font></h4>\n    </strong>\n</div>\n","metadata":{}},{"cell_type":"code","source":"# create data for Pie Chart\nplt.figure(figsize=(13, 8), dpi=80)\npichart = count_values_in_column(df,\"category\")\nnames= [\"Positive\",\"Neutral\",\"Negative\",\"Nan\"]\nsize=pichart[\"Percentage\"]\n \n# Create a circle for the center of the plot\nmy_circle=plt.Circle( (0,0), 0.5, color='white')\nplt.pie(size, labels=names, colors=['green','blue','red',\"yellow\"])\np=plt.gcf()\np.gca().add_artist(my_circle)\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function to Create Wordcloud\ndef create_wordcloud(text,path):\n    stopwords = set(STOPWORDS)\n    wc = WordCloud(background_color=\"white\",\n    max_words=3000,\n    stopwords=stopwords,\n    random_state=42,\n    width=900, height=500,\n    repeat=True)\n    wc.generate(str(text))\n    wc.to_file(path)\n    print(\"Word Cloud Saved Successfully\")\n    path=path\n    display(Image.open(path))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Parameters of wordcloud function<br>\n<font color = \"brown\" size = 3.5>\n<li>background_color = Color of background</li><br>\n<li>max_words = The maximum number of unique words used</li><br>\n<li>stopwords = stopword list</li><br>\n<li>max_font_size = Maximum font size</li><br>\n<li>random_state = To ensure that random numbers are generated in the</li><br>\n<li>same order, so the results will be the same even if generated several times</li><br>\n<li>width = width size of the output</li><br>\n<li>height = height size of the output</li><br></font>","metadata":{}},{"cell_type":"code","source":"# Wordcloud for all tweets\nplt.figure(figsize=(15, 8), dpi=80)\ncreate_wordcloud(df['clean_text'].values,\"all.png\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Wordcloud for only positive tweets\nplt.figure(figsize=(15, 8), dpi=80)\ncreate_wordcloud(df_positive['clean_text'].values,\"positive.png\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Wordcloud for only negative tweets\nplt.figure(figsize=(15, 8), dpi=80)\ncreate_wordcloud(df_negative['clean_text'].values,\"negative.png\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Wordcloud for only neutral tweets\nplt.figure(figsize=(15, 8), dpi=80)\ncreate_wordcloud(df_neutral['clean_text'].values,\"neutral.png\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"background:#c72e57;color:#fff;padding:1em 2em 1.5em 2em;border-radius: 3px;font-weight:bold\">\n    <strong>\n        <h4 style = \"color:#fff\"><font size = 4>5. Data Preprocessing</font></h4>\n    </strong>\n</div>\n","metadata":{}},{"cell_type":"code","source":"# df = df.dropna()\n# df = df.reset_index()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Stemming\n# ps = PorterStemmer()\n# corpus = []\n# for i in range(0, len(df)):\n#     # Removing characters other than letters\n#     review = re.sub('[^a-zA-Z]', ' ', str(df[\"clean_text\"][i]))\n#     # Lowering the case all the text\n#     review = review.lower()\n#     # Splitting into words\n#     review = review.split()\n#     # Applying Stemming\n#     review = [ps.stem(word) for word in review if not word in stopwords.words('english')]\n#     # Joining words\n#     review = ' '.join(review)\n#     # Appending all tweets to a list after preprocessing\n#     corpus.append(review)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# len(corpus)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# df[\"clean_text\"] = corpus","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# df = df.dropna()\n# df = df.reset_index()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.isna().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# df[[\"clean_text\",\"category\"]].to_csv(\"stemmed.csv\",index = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_stemmed = pd.read_csv(\"../input/stemmed/stemmed.csv\")\ncorpus = list(df_stemmed[\"clean_text\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Applying Count Vectorization\ncount = CountVectorizer(max_features=5000,ngram_range=(1,3))\nX_count = count.fit_transform(corpus).toarray()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Applying TFIDF Vectorization\ntfidf = TfidfVectorizer(max_features=5000,ngram_range=(1,3))\nX_tfidf = tfidf.fit_transform(corpus).toarray()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Y=df_stemmed[\"category\"]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train_count,X_test_count,Y_train_count,Y_test_count = train_test_split(X_count,Y,test_size=0.33,random_state = 27)\nX_train_tfidf,X_test_tfidf,Y_train_tfidf,Y_test_tfidf = train_test_split(X_tfidf,Y,test_size=0.33,random_state = 27)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}